{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build the dataset\n",
    "\n",
    "How we collect and buid our dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Download the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To obtain data for our face verification system, we use several methods:\n",
    "\n",
    "- Use pre-built datasets, in this case the LFW dataset\n",
    "\n",
    "- Use web scraping to collect data from the internet\n",
    "\n",
    "- Use video or image processing to collect data from real-world sources or capture data using webcam devices or video formats\n",
    "\n",
    "More details about each method are discussed in the following sections. Regardless of the method you choose to add data, create a folder named `data` inside the project folder and add all your data there.\n",
    "\n",
    "Note that this `data` folder is not committed to the repository, so run the following code to create it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory if it doesn't exist\n",
    "import os\n",
    "os.makedirs('data', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 1.1 Pre build dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Access this [link](http://vis-www.cs.umass.edu/lfw/) to download the LFW dataset.\n",
    "\n",
    "Download -> All images as gzipped tar file -> lfw.tgz. Then move to the project workspace and extract the file using:\n",
    "\n",
    "```bash\n",
    "tar -xvzf lfw.tgz\n",
    "```\n",
    "\n",
    "After that, observe the `data` folder, you will see subfolders named after the person's name, each subfolder contains images of that person.\n",
    "\n",
    "\n",
    "![datasetView1](assets/images/datasetView1.png)\n",
    "\n",
    "\n",
    "The dataset is composed of 13233 images of 5749 people. The dataset is devicded into many subfolders, each subfolder contains images of a specific person. Each image is named as the person's name and a number, size of the image is 250x250 pixels and in JPEG format. The strucutre of the dataset is as follows:\n",
    "\n",
    "```plaintext\n",
    "lfw\n",
    "│\n",
    "|───person_1\n",
    "│   │   person_1_001.jpg\n",
    "│   │   person_1_002.jpg\n",
    "│   │   ...\n",
    "│\n",
    "|───person_2\n",
    "│   │   person_2_001.jpg\n",
    "│   │   person_2_002.jpg\n",
    "│   │   ...\n",
    "```\n",
    "\n",
    "Beside this dataset, we plan to use open source datasets provided by the University of Essex (face94, face95 and face96) if we have time and resources.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Collecting data from the internet using web scraping\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We use the below script to collect images from the internet using the `simple_image_download` library. Specify the person's name as the keyword, it will search for images of that person and download them to a folder named after the person's name. Note that using this, you will need to manually verify the images to ensure they are of the correct person.\n",
    "\n",
    "```python\n",
    "from simple_image_download import simple_image_download as simp\n",
    "\n",
    "# from simp library call simple_image_download function\n",
    "response = simp.simple_image_download\n",
    "\n",
    "# the keywords that will be used to find pics, and each key work will create a different file \n",
    "keywords = [\"George Wassouf\", \"Donald Trump\", \"Selena Gomez\"]\n",
    "\n",
    "# for loop on the keywords\n",
    "# (kw, 1000) means 300 sample of each keyword \n",
    "for kw in keywords:\n",
    "    response().download(kw, 1000) \n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Collecting data from the real world using webcam devices or video format\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "```python\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Input Path\n",
    "video_path = '/home/jawabreh/Desktop/face_scan.MOV'\n",
    "\n",
    "# Output Path\n",
    "output_dir = '/home/jawabreh/Desktop/face-recognition/training/person_1'\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Create a VideoCapture object to read the input video\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Get the total number of frames in the video\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Calculate the frame interval to capture for 150 images\n",
    "frame_interval = total_frames // 1000 # change this number according to your needs \n",
    "\n",
    "# Set the initial frame counter to 0\n",
    "frame_counter = 0\n",
    "\n",
    "while cap.isOpened():\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Check if this is the frame to capture\n",
    "    if frame_counter % frame_interval == 0 and frame_counter // frame_interval < 1000:\n",
    "        # Save the frame as a JPEG image\n",
    "        output_path = os.path.join(output_dir, f'{frame_counter//frame_interval + 1:03}.jpg')\n",
    "        cv2.imwrite(output_path, frame)\n",
    "    \n",
    "    # Increment the frame counter\n",
    "    frame_counter += 1\n",
    "    \n",
    "    if frame_counter >= total_frames:\n",
    "        break\n",
    "\n",
    "# Release the video capture object\n",
    "cap.release()\n",
    "print(\"\\n\\nDONE\\n\\n\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**An alternative way to capture images from a webcam is to use the following script, using p to capture an image and q to quit the program instead of using a video**:\n",
    "\n",
    "```python\n",
    "# Defined the Camera ID to use\n",
    "CAM_ID = 3 # Establishing the connection with the IR camera\n",
    "\n",
    "import cv2\n",
    "import os\n",
    "import uuid\n",
    "\n",
    "# Function to save the captured image to the specified folder\n",
    "def save_image(image, folder_path, img_name):\n",
    "    img_path = os.path.join(folder_path, img_name)\n",
    "    cv2.imwrite(img_path, image)\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(CAM_ID)\n",
    "\n",
    "\n",
    "# Get the name of the person to store in training data\n",
    "name = input(\"Name of the person to store in training data: \")\n",
    "\n",
    "# Loop through every frame in the webcam feed\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Display the frame\n",
    "    cv2.imshow('Face collect for as training data, press `p` to cpture, `q` for quit', frame)\n",
    "    \n",
    "    # Check for key presses\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('p'):\n",
    "        # Save the frame to './data' folder\n",
    "        save_path = os.path.join('data', name)\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "        save_image(frame, save_path, str(uuid.uuid1()) + \".jpg\")\n",
    "        print(\"Image saved to\", save_path)\n",
    "\n",
    "    elif key == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "```\n",
    "\n",
    "The above code will prompt usr to enter name, then it will capture images from the webcam when press `p` and save them to a folder named after the person's name inside the `data` folder.\n",
    "\n",
    "\n",
    "- CAM_ID = 0 for laptop normal webcam\n",
    "- CAM_ID = 2 for laptop IR webcam\n",
    "- CAM_ID = 4 for external webcam\n",
    "\n",
    "\n",
    "***Depend on each devices, these number can be different. Try out all number start from 0 and see which one is the correct one on your device.***\n",
    "\n",
    "\n",
    "Set up camera:\n",
    "\n",
    "**IR webcam:**\n",
    "\n",
    "What is IR webcam? https://fptshop.com.vn/tin-tuc/danh-gia/ir-camera-la-gi-153147\n",
    "\n",
    "\n",
    "**External webcam**\n",
    "\n",
    "Since the resolution of the laptop webcam is not good, we will use an external webcam like from a mobile phone. To connect the webcam to the laptop:\n",
    "\n",
    "1. Download the DroidCam app on your phone, also the DroidCam client on your laptop: https://www.dev47apps.com/\n",
    "2. Set up as the instruction on the website. With Linux:\n",
    "\n",
    "```bash\n",
    "wget -O droidcam_latest.zip https://files.dev47apps.net/linux/droidcam_2.1.3.zip\n",
    "unzip droidcam_latest.zip -d droidcam\n",
    "cd droidcam && sudo ./install-client\n",
    "sudo apt install libappindicator3-1\n",
    "\n",
    "# Fix missing video device\n",
    "sudo apt install linux-headers-`uname -r` gcc make\n",
    "sudo ./install-video\n",
    "```\n",
    "3. Open both DroidCam on phone and DroidCam client on laptop, connect the phone to the laptop via USB or Wifi.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **NOTE:** Currently, we are just testing on the LWF dataset, but use the second and third methods can be use to enhace the diversity or specific data we need for our face verification system. Most of iamges inside the LWF dataset are people in Western countries, so we can use the second and third methods to collect images of people from our specific region or country. This will help the model perfrom better on our target market."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.4 Reduce amount of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incase you want to run this notebook on your machine, but the size of LWF dataset overwhelms your machine, you can run the following code delete some random subfolders from the dataset, only keeping as you want.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lfw_dir = './lfw' # REPLACE WITH YOUR PATH to the LFW dataset (after extracting the zip file)\n",
    "# In my case, it located in the same directory as this notebook\n",
    "\n",
    "# We do not wnat to modify/delete directly the original lfw dataset, \n",
    "# so we will copy it to the `data` directory we created before and process\n",
    "data_dir = './data'\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Create the data folder if it doesn't exist\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "# Copy the content of the lfw folder to the data folder\n",
    "for item in os.listdir(lfw_dir):\n",
    "    s = os.path.join(lfw_dir, item)\n",
    "    d = os.path.join(data_dir, item)\n",
    "    if os.path.isdir(s):\n",
    "        if not os.path.exists(d):\n",
    "            shutil.copytree(s, d)\n",
    "        else:\n",
    "            for sub_item in os.listdir(s):\n",
    "                sub_s = os.path.join(s, sub_item)\n",
    "                sub_d = os.path.join(d, sub_item)\n",
    "                if os.path.isdir(sub_s):\n",
    "                    shutil.copytree(sub_s, sub_d, dirs_exist_ok=True)\n",
    "                else:\n",
    "                    shutil.copy2(sub_s, sub_d)\n",
    "    else:\n",
    "        shutil.copy2(s, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kept 20 subfolders and deleted the rest.\n"
     ]
    }
   ],
   "source": [
    "# Perform randomly delete subfolders to reudce the size of the dataset\n",
    "\n",
    "import random\n",
    "\n",
    "# Get a list of all subfolders\n",
    "subfolders = [f.path for f in os.scandir(data_dir) if f.is_dir()]\n",
    "\n",
    "# Shuffle the list of subfolders\n",
    "random.shuffle(subfolders)\n",
    "\n",
    "# Keep only 20 subfolders\n",
    "subfolders_to_keep = subfolders[:20]\n",
    "\n",
    "# Delete the remaining subfolders\n",
    "for subfolder in subfolders[20:]:\n",
    "    for root, dirs, files in os.walk(subfolder, topdown=False):\n",
    "        for name in files:\n",
    "            os.remove(os.path.join(root, name))\n",
    "        for name in dirs:\n",
    "            os.rmdir(os.path.join(root, name))\n",
    "    os.rmdir(subfolder)\n",
    "\n",
    "print(f\"Kept {len(subfolders_to_keep)} subfolders and deleted the rest.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Arrangement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create augmented images and store them in the same folder as the original images, which is the `data` folder.\n",
    "\n",
    "Inside the `data` folder, there are many subfolders, each containing images of a person. The number of images in each subfolder varies. Count the number of images in each subfolder. If a subfolder has many images (high density), apply only a few augmentation operations to each image. Otherwise (low density), apply more augmentations to each image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import random\n",
    "\n",
    "# For argumetation operations\n",
    "from albumentations import (\n",
    "    Compose,\n",
    "    RandomBrightnessContrast,\n",
    "    VerticalFlip,\n",
    "    HorizontalFlip,\n",
    "    Rotate,\n",
    "    ShiftScaleRotate,\n",
    "    HueSaturationValue,\n",
    "    GaussianBlur,\n",
    "    GaussNoise,\n",
    "    ElasticTransform,\n",
    "    GridDistortion,\n",
    "    CLAHE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count number of images inside each subfolder, if there are quite many (high density)\n",
    "# we will only a few argumetation operations to each image, othersise,(low density) we will apply more augmentations to each image.\n",
    "def count_images(folder):\n",
    "    \"\"\"Count number of image files in folder\"\"\"\n",
    "    return len([f for f in os.listdir(folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "\n",
    "\n",
    "# Based on the number of images in a folder (density), we will decide the how many augmentations we will apply to each image.\n",
    "def create_augmentations(density='high'):\n",
    "    \"\"\"Create list of augmentations based on density\"\"\"\n",
    "    if density == 'high':\n",
    "        # Limited augmentations with high density\n",
    "        augmentations = [\n",
    "            RandomBrightnessContrast(p=1.0),\n",
    "            HorizontalFlip(p=1.0),\n",
    "        ]\n",
    "    else:\n",
    "        # More augmentations: Brightless,Horizontal Flip, Rotate, Zoom, Vary color, ...\n",
    "        augmentations = [\n",
    "            RandomBrightnessContrast(p=1.0),\n",
    "            HorizontalFlip(p=1.0),\n",
    "            Rotate(limit=60, p=1.0),\n",
    "            ShiftScaleRotate(\n",
    "                shift_limit=0.3,\n",
    "                scale_limit=0.3,\n",
    "                rotate_limit=20,\n",
    "                p=1.0\n",
    "            ),\n",
    "            HueSaturationValue(p=1.0),\n",
    "        ]\n",
    "    return augmentations\n",
    "\n",
    "\n",
    "# Augment images in a folder using predefined density transformations\n",
    "def augment_folder(folder_path, density):\n",
    "    \"\"\"Augment images in folder using predefined density transformations\"\"\"\n",
    "    augmentations = create_augmentations(density)\n",
    "    image_files = [f for f in os.listdir(folder_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "    # Randomly decide how many images to augment (both in the number and which images)\n",
    "    num_to_augment = random.randint(1, len(os.listdir(folder_path)))\n",
    "    images_to_augment = random.sample(os.listdir(folder_path), num_to_augment)\n",
    "    \n",
    "    for img_name in images_to_augment:\n",
    "        img_path = os.path.join(folder_path, img_name)\n",
    "        try:\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                continue\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            for aug in augmentations:\n",
    "                # Apply each augmentation separately\n",
    "                augmented = aug(image=img)\n",
    "                augmented_image = augmented[\"image\"]\n",
    "                \n",
    "                filename, ext = os.path.splitext(img_name)\n",
    "                aug_name = aug.__class__.__name__\n",
    "                aug_filename = f\"{filename}_{aug_name}{ext}\"\n",
    "                aug_path = os.path.join(folder_path, aug_filename)\n",
    "                \n",
    "                aug_bgr = cv2.cvtColor(augmented_image, cv2.COLOR_RGB2BGR)\n",
    "                cv2.imwrite(aug_path, aug_bgr) # Store  name of original image + augmentation type\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {img_path}: {str(e)}\")\n",
    "            \n",
    "    print(f\"Augmentation completed for folder: {folder_path} with density: {density}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Augmentation completed for folder: data/Robert_Lee_Yates_Jr with density: low\n",
      "Augmentation completed for folder: data/Stan_Kroenke with density: low\n",
      "Augmentation completed for folder: data/Raza_Rabbani with density: low\n",
      "Augmentation completed for folder: data/Bill_Byrne with density: low\n",
      "Augmentation completed for folder: data/Kevin_Tarrant with density: low\n",
      "Augmentation completed for folder: data/TA_McLendon with density: low\n",
      "Augmentation completed for folder: data/Michael_Shelby with density: low\n",
      "Augmentation completed for folder: data/Arthur_Johnson with density: low\n",
      "Augmentation completed for folder: data/Francisco_Garcia with density: low\n",
      "Augmentation completed for folder: data/Zahir_Shah with density: low\n",
      "Augmentation completed for folder: data/Ellen_Pompeo with density: low\n",
      "Augmentation completed for folder: data/Elizabeth_Hurley with density: high\n",
      "Augmentation completed for folder: data/Paul_Coppin with density: low\n",
      "Augmentation completed for folder: data/Rick_Husband with density: low\n",
      "Augmentation completed for folder: data/Soenarno with density: low\n",
      "Augmentation completed for folder: data/Laurie_Pirtle with density: low\n",
      "Augmentation completed for folder: data/Jane_Rooney with density: low\n",
      "Augmentation completed for folder: data/Sandra_Ceccarelli with density: low\n",
      "Augmentation completed for folder: data/Ralph_Sampson with density: low\n",
      "Augmentation completed for folder: data/Carlos_Alberto_Parreira with density: low\n"
     ]
    }
   ],
   "source": [
    "data_directory = 'data'\n",
    "DENSITY_THRESHOLD = 3 # If inside as folder, there are more than 3 images, we consider it as high density, otherwise, low density\n",
    "\n",
    "# fProcessing each subfolder in the data directory\n",
    "for subfolder in os.listdir(data_directory):\n",
    "    folder_path = os.path.join(data_directory, subfolder)\n",
    "    if os.path.isdir(folder_path):\n",
    "        num_images = count_images(folder_path)\n",
    "        if num_images > DENSITY_THRESHOLD:\n",
    "            density = 'high'\n",
    "        else:\n",
    "            density = 'low'\n",
    "        augment_folder(folder_path, density)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Complete data folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add your own data as you liek, just put all of them inside the `data` folder. The structure of the data folder should be as follows:\n",
    "\n",
    "```plaintext\n",
    "data\n",
    "│\n",
    "|───person_1\n",
    "│   │   person_1_001.jpg\n",
    "│   │   person_1_002.jpg\n",
    "│   │   ...\n",
    "│\n",
    "|───person_2\n",
    "│   │   person_2_001.jpg\n",
    "│   │   person_2_002.jpg\n",
    "│   │   ...\n",
    "```\n",
    "\n",
    "Now, we already have the dataset, we continue to preprocessing these data for the training process. \n",
    "\n",
    "- For the first pipleine (Facenet + SVM), check the data process inside the `Pipeline1 DataPreprocessing.ipynb` notebook, then the training pharse inside the `SVM_Classifier.ipynb` notebook.\n",
    "\n",
    "- For the second pipeline (Siamese Architecture + L1 distance), the preprocessing data process is inside the `Pipeline2 DataPreprocessing.ipynb` notebook, then the training pharse inside the `Siamese_Network.ipynb` notebook."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
